# Train parameters
model: bert-base-uncased
tokenizer: bert-base-uncased
pretrained: True
optimizer: AdamW
scheduler: LinearLambdaLR
batch-size: 1
max-length: 512
max-epochs: 100
num-trials: 1
loss: cross_entropy
clip-grad: 1.0
optimizer-kwargs:
  lr: 0.00005
scheduler-kwargs:
  num_warmup_steps: 0
mask: False

# Data Parameters
name: smcalflow
train-src: _test-dataset/train.json
val-src: _test-dataset/valid.json
task: nmt
overwrite_cache: True
num-workers: 4
max-train-samples: 100
max-val-samples: 100

# io
output: _test-output
checkpoint: _test-checkpoint
cache-dir: _test-cache
save-freq: 1
